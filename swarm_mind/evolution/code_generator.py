# The MIT License (MIT)
# Copyright ¬© 2025 <kisa134>

import ast
import inspect
import os
import re
import requests
from typing import Dict, List, Any, Optional, Tuple
import astor
import subprocess
import tempfile
import sys
from swarm_mind.logger import log_event


class CodeGenerator:
    """
    ü§ñ –ê–í–¢–û–ù–û–ú–ù–´–ô –ì–ï–ù–ï–†–ê–¢–û–† –ö–û–î–ê ü§ñ
    
    –≠—Ç–æ—Ç –º–æ–¥—É–ª—å –º–æ–∂–µ—Ç:
    1. –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥
    2. –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —É–ª—É—á—à–µ–Ω–∏—è —á–µ—Ä–µ–∑ LLM
    3. –°–æ–∑–¥–∞–≤–∞—Ç—å –Ω–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏ –∫–ª–∞—Å—Å—ã
    4. –†–µ—Ñ–∞–∫—Ç–æ—Ä–∏—Ç—å –∫–æ–¥ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
    5. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Ä–µ–¥–µ
    """
    
    def __init__(self, ollama_url: str = "http://localhost:11434", model: str = "deepseek-r1:latest"):
        self.ollama_url = ollama_url
        self.model = model
        self.generated_code_history = []
        
        print("ü§ñ [CODE-GENERATOR] Initializing autonomous code generation...")
        print("‚ö° [CODE-GENERATOR] Ready to write and improve code autonomously!")
    
    async def analyze_codebase(self, directory: str = "./swarm_mind") -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –≤—Å–µ–π –∫–æ–¥–æ–≤–æ–π –±–∞–∑—ã"""
        print(f"üîç [ANALYSIS] Scanning codebase in {directory}...")
        
        analysis = {
            'total_files': 0,
            'total_lines': 0,
            'functions': [],
            'classes': [],
            'imports': set(),
            'complexity_score': 0,
            'technical_debt': [],
            'optimization_opportunities': []
        }
        
        for root, dirs, files in os.walk(directory):
            for file in files:
                if file.endswith('.py'):
                    file_path = os.path.join(root, file)
                    file_analysis = await self.analyze_python_file(file_path)
                    
                    analysis['total_files'] += 1
                    analysis['total_lines'] += file_analysis['lines']
                    analysis['functions'].extend(file_analysis['functions'])
                    analysis['classes'].extend(file_analysis['classes'])
                    analysis['imports'].update(file_analysis['imports'])
                    analysis['complexity_score'] += file_analysis['complexity']
                    analysis['technical_debt'].extend(file_analysis['debt'])
        
        print(f"üìä [ANALYSIS] Found {analysis['total_files']} files, {analysis['total_lines']} lines")
        print(f"üèóÔ∏è [ANALYSIS] {len(analysis['functions'])} functions, {len(analysis['classes'])} classes")
        
        return analysis
    
    async def analyze_python_file(self, file_path: str) -> Dict[str, Any]:
        """–ü–æ–¥—Ä–æ–±–Ω—ã–π –∞–Ω–∞–ª–∏–∑ Python —Ñ–∞–π–ª–∞"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                source_code = f.read()
            
            tree = ast.parse(source_code)
            
            analysis = {
                'file_path': file_path,
                'lines': len(source_code.split('\n')),
                'functions': [],
                'classes': [],
                'imports': [],
                'complexity': 0,
                'debt': []
            }
            
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    func_info = {
                        'name': node.name,
                        'line': node.lineno,
                        'args': len(node.args.args),
                        'docstring': ast.get_docstring(node),
                        'complexity': self.calculate_complexity(node)
                    }
                    analysis['functions'].append(func_info)
                    analysis['complexity'] += func_info['complexity']
                    
                    # –ò—â–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –¥–æ–ª–≥
                    if func_info['complexity'] > 10:
                        analysis['debt'].append(f"High complexity function: {node.name}")
                    if not func_info['docstring']:
                        analysis['debt'].append(f"Missing docstring: {node.name}")
                        
                elif isinstance(node, ast.ClassDef):
                    class_info = {
                        'name': node.name,
                        'line': node.lineno,
                        'methods': len([n for n in node.body if isinstance(n, ast.FunctionDef)]),
                        'docstring': ast.get_docstring(node)
                    }
                    analysis['classes'].append(class_info)
                    
                elif isinstance(node, (ast.Import, ast.ImportFrom)):
                    if isinstance(node, ast.Import):
                        for alias in node.names:
                            analysis['imports'].append(alias.name)
                    else:
                        analysis['imports'].append(node.module or '')
            
            return analysis
            
        except Exception as e:
            print(f"‚ùå [ANALYSIS] Error analyzing {file_path}: {e}")
            return {'file_path': file_path, 'lines': 0, 'functions': [], 'classes': [], 'imports': [], 'complexity': 0, 'debt': []}
    
    def calculate_complexity(self, node: ast.AST) -> int:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ü–∏–∫–ª–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏"""
        complexity = 1  # –ë–∞–∑–æ–≤–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å
        
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.Try, ast.With)):
                complexity += 1
            elif isinstance(child, ast.BoolOp):
                complexity += len(child.values) - 1
                
        return complexity
    
    async def generate_code_improvements(self, analysis: Dict[str, Any]) -> List[Dict]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–∏–π –∫–æ–¥–∞ —á–µ—Ä–µ–∑ LLM"""
        print("üß† [AI-CODING] Asking AI to generate code improvements...")
        
        # –ì–æ—Ç–æ–≤–∏–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        high_complexity_funcs = [f for f in analysis['functions'] if f['complexity'] > 8]
        missing_docs = [f for f in analysis['functions'] if not f['docstring']]
        
        prompt = f"""
You are an expert Python developer analyzing code for improvements.

Codebase Analysis:
- Total files: {analysis['total_files']}
- Total lines: {analysis['total_lines']}
- Functions: {len(analysis['functions'])}
- Classes: {len(analysis['classes'])}
- Average complexity: {analysis['complexity_score'] / max(len(analysis['functions']), 1):.1f}

Issues Found:
- High complexity functions: {len(high_complexity_funcs)}
- Missing docstrings: {len(missing_docs)}
- Technical debt items: {len(analysis['technical_debt'])}

Generate 3 specific code improvements. For each, provide:
1. Type of improvement (refactor/optimize/document/test)
2. Target function/class
3. Complete new code implementation
4. Explanation of benefits

Focus on:
- Performance optimizations
- Better error handling
- Code readability
- Adding missing features

Respond in JSON format:
{{
  "improvements": [
    {{
      "type": "optimize",
      "target": "function_name",
      "file": "path/to/file.py",
      "new_code": "complete Python code here",
      "explanation": "This optimization reduces time complexity from O(n¬≤) to O(n)",
      "estimated_benefit": "50% performance improvement"
    }}
  ]
}}
"""
        
        try:
            response = await self.call_ollama(prompt)
            
            # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
            import re
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                import json
                improvements_data = json.loads(json_match.group())
                
                print(f"üí° [AI-CODING] Generated {len(improvements_data.get('improvements', []))} code improvements")
                log_event('CodeGenerator: generated code improvements')
                return improvements_data.get('improvements', [])
                
        except Exception as e:
            print(f"‚ùå [AI-CODING] Error generating improvements: {e}")
        
        return []
    
    async def generate_new_module(self, purpose: str, requirements: List[str]) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ –º–æ–¥—É–ª—è —Å –Ω—É–ª—è"""
        print(f"üÜï [NEW-MODULE] Generating module for: {purpose}")
        
        prompt = f"""
Create a complete Python module for: {purpose}

Requirements:
{chr(10).join(f'- {req}' for req in requirements)}

Generate a complete, production-ready Python module with:
1. Proper imports
2. Class definitions with docstrings
3. Error handling
4. Type hints
5. Unit tests (if applicable)
6. Example usage

The module should follow Python best practices and be immediately usable.

Provide ONLY the Python code, no explanations:
"""
        
        try:
            response = await self.call_ollama(prompt)
            
            # –û—á–∏—â–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            code = re.sub(r'^```python\n', '', response, flags=re.MULTILINE)
            code = re.sub(r'\n```$', '', code, flags=re.MULTILINE)
            
            print(f"‚úÖ [NEW-MODULE] Generated {len(code.split(chr(10)))} lines of code")
            log_event(f'CodeGenerator: generated new module {purpose}')
            return code
            
        except Exception as e:
            print(f"‚ùå [NEW-MODULE] Error generating module: {e}")
            return ""
    
    async def optimize_function(self, function_code: str, context: str = "") -> str:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏"""
        print("‚ö° [OPTIMIZE] Optimizing function performance...")
        
        prompt = f"""
Optimize this Python function for better performance, readability, and error handling:

```python
{function_code}
```

Context: {context}

Provide the optimized version with:
1. Better performance (reduce time/space complexity)
2. Improved error handling
3. Type hints
4. Better variable names
5. Docstring with examples

Return ONLY the optimized Python code:
"""
        
        try:
            response = await self.call_ollama(prompt)
            
            # –û—á–∏—â–∞–µ–º –∫–æ–¥
            code = re.sub(r'^```python\n', '', response, flags=re.MULTILINE)
            code = re.sub(r'\n```$', '', code, flags=re.MULTILINE)
            
            return code
            
        except Exception as e:
            print(f"‚ùå [OPTIMIZE] Error optimizing function: {e}")
            return function_code
    
    async def test_generated_code(self, code: str, file_path: str = None) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–¥–∞"""
        print("üß™ [TESTING] Testing generated code...")
        
        test_results = {
            'syntax_valid': False,
            'imports_valid': False,
            'runtime_errors': [],
            'warnings': [],
            'score': 0
        }
        
        try:
            # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞
            ast.parse(code)
            test_results['syntax_valid'] = True
            test_results['score'] += 25
            print("‚úÖ [TESTING] Syntax is valid")
            
            # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤ –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Ä–µ–¥–µ
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as tmp_file:
                tmp_file.write(code)
                tmp_file_path = tmp_file.name
            
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–º–ø–æ—Ä—Ç—ã
                result = subprocess.run([
                    sys.executable, '-c',
                    f'import ast; ast.parse(open("{tmp_file_path}").read()); print("OK")'
                ], capture_output=True, text=True, timeout=10)
                
                if result.returncode == 0:
                    test_results['imports_valid'] = True
                    test_results['score'] += 25
                    print("‚úÖ [TESTING] Imports are valid")
                else:
                    test_results['runtime_errors'].append(result.stderr)
                    print("‚ùå [TESTING] Import errors found")
                    
            except subprocess.TimeoutExpired:
                test_results['warnings'].append("Code execution timeout")
                
            finally:
                os.unlink(tmp_file_path)
            
            # 3. –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
            if test_results['syntax_valid']:
                tree = ast.parse(code)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω–∞–ª–∏—á–∏–µ docstrings
                functions = [node for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]
                classes = [node for node in ast.walk(tree) if isinstance(node, ast.ClassDef)]
                
                documented_funcs = sum(1 for func in functions if ast.get_docstring(func))
                documented_classes = sum(1 for cls in classes if ast.get_docstring(cls))
                
                total_items = len(functions) + len(classes)
                if total_items > 0:
                    doc_score = (documented_funcs + documented_classes) / total_items * 25
                    test_results['score'] += doc_score
                
                # –ë–æ–Ω—É—Å –∑–∞ type hints
                if 'typing' in code or '->' in code or ': ' in code:
                    test_results['score'] += 25
                    print("‚úÖ [TESTING] Type hints detected")
            
            print(f"üìä [TESTING] Overall score: {test_results['score']:.1f}/100")
            
        except SyntaxError as e:
            test_results['runtime_errors'].append(f"Syntax error: {e}")
            print(f"‚ùå [TESTING] Syntax error: {e}")
        except Exception as e:
            test_results['runtime_errors'].append(f"Unexpected error: {e}")
            print(f"‚ùå [TESTING] Unexpected error: {e}")
        
        return test_results
    
    async def apply_code_to_file(self, file_path: str, new_code: str, backup: bool = True) -> bool:
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–¥–∞ –∫ —Ñ–∞–π–ª—É"""
        try:
            if backup and os.path.exists(file_path):
                backup_path = f"{file_path}.backup_{int(__import__('time').time())}"
                with open(file_path, 'r', encoding='utf-8') as src:
                    with open(backup_path, 'w', encoding='utf-8') as dst:
                        dst.write(src.read())
                print(f"üíæ [BACKUP] Created backup: {backup_path}")
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–æ–¥ –ø–µ—Ä–µ–¥ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º
            test_results = await self.test_generated_code(new_code, file_path)
            
            if test_results['score'] >= 50:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –∫–∞—á–µ—Å—Ç–≤–∞
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(new_code)
                print(f"‚úÖ [APPLIED] Code successfully applied to {file_path}")
                return True
            else:
                print(f"‚ùå [REJECTED] Code quality too low: {test_results['score']:.1f}/100")
                return False
                
        except Exception as e:
            print(f"‚ùå [APPLY] Error applying code: {e}")
            return False
    
    async def call_ollama(self, prompt: str) -> str:
        """–í—ã–∑–æ–≤ Ollama API"""
        try:
            payload = {
                "model": self.model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.2,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –±–æ–ª–µ–µ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–¥–∞
                    "max_tokens": 2000
                }
            }
            
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json=payload,
                timeout=60  # –ë–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞
            )
            
            if response.status_code == 200:
                return response.json().get("response", "")
            else:
                print(f"‚ùå [OLLAMA] API error: {response.status_code}")
                return ""
                
        except Exception as e:
            print(f"‚ùå [OLLAMA] Error: {e}")
            return ""

# üåü –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –° –û–°–ù–û–í–ù–û–ô –°–ò–°–¢–ï–ú–û–ô

async def start_autonomous_coding():
    """–ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –∫–æ–¥–∏–Ω–≥–∞"""
    generator = CodeGenerator()
    
    print("üöÄ [AUTONOMOUS-CODING] Starting autonomous code generation...")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∫–æ–¥–æ–≤—É—é –±–∞–∑—É
    analysis = await generator.analyze_codebase()
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–ª—É—á—à–µ–Ω–∏—è
    improvements = await generator.generate_code_improvements(analysis)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –ª—É—á—à–∏–µ —É–ª—É—á—à–µ–Ω–∏—è
    for improvement in improvements[:2]:  # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç–æ–ª—å–∫–æ 2 –ª—É—á—à–∏—Ö
        if improvement.get('new_code'):
            print(f"üîß [APPLYING] {improvement['type']} for {improvement['target']}")
            # –í —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ –∑–¥–µ—Å—å –±—ã–ª–æ –±—ã –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫–æ–¥–∞
            print(f"üìù [PREVIEW] {improvement['new_code'][:200]}...")
    
    return generator

def integrate_code_generation():
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –∫–æ–¥–∞ —Å SwarmMind"""
    print("üîó [INTEGRATION] Code generator integrated with SwarmMind")
    print("ü§ñ [STATUS] System can now write and improve its own code!")
    return CodeGenerator() 